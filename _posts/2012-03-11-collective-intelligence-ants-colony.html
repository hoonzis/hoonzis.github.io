---
layout: post
title: 'Collective Intelligence: Ants colony solving TSP'
date: '2012-03-11T09:28:00.002-07:00'
author: Jan Fajfr
tags:
- Graph Theory
- Computer Science
modified_time: '2014-06-26T14:32:38.704-07:00'
thumbnail: http://lh5.ggpht.com/-VaL2wQPsE0c/T1zSaKKs13I/AAAAAAAAARY/XoUW14IDx2A/s72-c/stable_2_thumb.jpg?imgmax=800
blogger_id: tag:blogger.com,1999:blog-1710034134179566048.post-3402269271418485750
blogger_orig_url: http://hoonzis.blogspot.com/2012/03/collective-intelligence-ants-colony.html
---

<p>According to <a href="http://en.wikipedia.org/wiki/Collective_intelligence">wikipedia</a>: </p><p>“<b>Collective intelligence</b> is a shared or <a href="http://en.wikipedia.org/wiki/Group_intelligence">group intelligence</a> that emerges from the collaboration and competition of many individuals and appears in <a href="http://en.wikipedia.org/wiki/Consensus_decision_making">consensus decision making</a> in bacteria, animals, humans and computer networks”.</p><p>This article describes, how to make the ants, find the solution for TSP problem. Implemented in Python. <a href="https://github.com/hoonzis/CollectiveInteligence">Get the source from GitHUb.</a></p><p><a href="http://lh6.ggpht.com/-kNmfOoe_p7k/T1zSZWtEl6I/AAAAAAAAARQ/1wkj52xfckc/s1600-h/stable_2%25255B2%25255D.jpg"><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="stable_2" border="0" alt="stable_2" src="http://lh5.ggpht.com/-VaL2wQPsE0c/T1zSaKKs13I/AAAAAAAAARY/XoUW14IDx2A/stable_2_thumb.jpg?imgmax=800" width="244" height="215"></a></p><p>The algorithms based on the collective intelligence have some “interesting” properties:</p><ul><li>decentralization<br /><li>parallelism<br /><li>flexibility, adaptability<br /><li>"robustness" (failures)<br /><li>auto-organization</li><br /></ul><p>These algorithms are inspired by the nature. Here are some examples of collective intelligence which can be observed in the nature:</p><ol><li>The swallows settle on wires before they are taking of for the next destination. There is no leader in the group. The decision whether to take of is taken collectively. The probability for the swallow to take of is getting higher when there are more swallows in the air. If the other swallows do not join, the swallow will again settle down on the wire. At one point the number of the swallows in the air reaches the “break-point” when all the swallows decide to take of.<br /><li>The <a href="http://en.wikipedia.org/wiki/Bee_learning_and_communication">bees perform a special “dance”</a> to show their peers where the foot-source is. This dance gives the information about the angle of the food source position with respect to the sun. All the bees do perform the dance when coming back in, which makes the algorithm adaptive.<br /><li>When the ant founds food, he lays down a "positive pheromone" on his way back. This pheromone evaporates during the time. The other ants sniff for this pheromone when choosing their route and prefer to go in places where the concentration of the pheromone is higher. The shorter the path to the food source is, more pheromone stays on the track before it evaporates. The more pheromone there is, more ants take this path. When there is a obstacle in the route – the algorithm adapts easily to knew situation. Again the shortest route to evict the obstacle is chosen in the shortest time. <a href="http://iridia.ulb.ac.be/dorigo/ACO/RealAnts.html">Some details here</a>.</li><br /></ol><p>There exist several applications of collective intelligence in engineering and optimization. The ants example has applications specially in routing. One of the basic problems which can be solved using an Ant colony is Travelling Salesman Problem.</p><h3>Travelling Salesman Problem</h3><p>Travelling Salesman Problem is a classical problem in the field of graph theory. Given n cities the salesman has to visit all of the nodes, come back to his starting location and and minimize traveled distance. Although the problem is NP - hard, several heuristic algorithms exists which obtain suitable results in polynomial time.</p><h3>Ant colony algorithm for TSP</h3><p>Ant colony algorithm was introduced in year 1997 by Italian researcher Marco Dorigo.</p><p>On the beginning the ants start to explore the graph. They choose their nodes randomly, until they visit all of the nodes. A this point the ant starts to copy his path back to his starting point. While he copies the path, on each edge he lays down certain amount of pheromone inversely proportional to the length of the tour. When each ant starts new route in each node he will compute the probability to choose an edge to continue his route. The probability of choosing edge e in each step is computed as follows. </p><p><a href="http://lh5.ggpht.com/-r08GGlA91oY/T1zSa9rVKBI/AAAAAAAAARc/TSr5RQx30Zw/s1600-h/image2.png"><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://lh5.ggpht.com/-5K1l4XO-26M/T1zSbs4O8mI/AAAAAAAAARo/8j6GilzEUxc/image_thumb.png?imgmax=800" width="244" height="76"></a></p><ul><li>π_e&nbsp; corresponds to the value of pheromone on the edge e.<br /><li>η_e corresponds to the quality of the route. We can estimate this value by the length of the edge η_e = 1/d_e where d_e is the length of the edge.<br /><li>J_e is a set of all the edges which the ant can use for his next step - includes all the edges except the one for which we compute the probability.<br /><li>α and β are coefficients used to manage the impact of the length of the finished route to affect the decision other ants.<br /><li>The amount of pheromone given to a certain edge is l = 1/routeLength^k, where k is a coefficient to amplify the impact of the length of the route to the decision.<br /><li>During the time the pheromone evaporates on the edges. The evaporation can be expressed as: π_e = (1-ρ)π_e</li><br /></ul><h3>The implementation in Python</h3><p>Most of what I have learned and presented here was done during Collective Intelligence intensive course at Telecom ParisTech done by <a href="http://perso.telecom-paristech.fr/~jld/">Jean-Luis Dessales</a>, being part of the Athens program. The implementation was done in Python but as a module to a <a href="http://perso.telecom-paristech.fr/~jld/Evolife/Description.html">EvoLife</a> program, which is a custom tool developed by <a href="http://perso.telecom-paristech.fr/~jld/">Jean-Luis Dessales</a> for scientific observations on genetic algorithms and collective intelligence algorithms. I have decided to make a stand-alone python program by taking the important bits out just for the Ants colony algorithm. I do almost never work in python, so for anyone out there if you see any big wrongdoing against the python culture, naming conventions etc, let me know.</p><p>The most important bits are in the Ant class. </p><pre class="prettyprint"><br />self.Action = 'SearchNextNode'<br />self.Node<br />self.Path = []<br />self.PathLength = 0<br />self.ToVisit = []<br />self.Visited = []<br /></pre><p>The <strong><em>Action</em></strong> field remembers the Ant’s actual state. Each action has a corresponding method associated with it. The <strong><em>Node</em></strong> field holds the actual field. In <strong><em>ToVisit</em></strong> and <strong><em>Visited</em></strong> the ant stores the Nodes that he had already visited or that he needs to visit in order to achieve TSP completeness. Here is the “move” method which is called repetitively for each ant:</p><pre class="prettyprint"><br />def moves(self):<br />#here is the ants move - one of the following actions is always selected<br />if self.Action == 'GoToNode':<br />self.goToNode()<br />if self.Action == 'SearchNextNode':<br />self.searchNextNode()<br />if self.Action == 'ReturnToStart':<br />self.returnToStart()<br />if self.Action == "GoToFirst":<br />self.goToFirst()</pre><p>The most important of these method is <strong><em>searchNextNode</em></strong>, where the ant searches for his next edges to explore. In this method the behavior described in previous paragraph has to be defined.</p><pre class="brush: py; auto-links: true; collapse: false; first-line: 1; gutter: true; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">def searchNextNode(self):<br />nodeindex = self.Node.Id        <br />#the maximal probability<br />pMax = 0<br />p = 0<br /><br />#Try to select the best node by the pheromones in the direction<br />#have to iterate over all nodes<br />for i in range(NbNodes):<br />if i!=self.Node.Id and self.Visited[i]==0:<br />d = Land.Distances[self.Node.Id][i]<br /><br />#get the value of pheromon on the edge<br />pi = Land.Edges[self.Node.Id][i]<br /><br />#To prevent division by zero and get some info<br />#when d = 0 there would be problem in computation of d<br />if d==0:<br />print i<br />print self.Node.Id<br /><br />#the quality of the route<br />nij = 1/d<br /><br />pselected = math.pow(pi,alfa) * math.pow(nij,beta)<br /><br />#normalization<br />#compute the sum of other options<br />sum = 0<br />for j in range(NbNodes):<br />if j!=self.Node.Id and self.Visited[j]==0 and j!=i:<br />dj = Land.Distances[self.Node.Id][j]<br />pij = Land.Edges[self.Node.Id][j]<br />nj = 1/dj<br />pj = math.pow(pij,alfa) * math.pow(nj,beta)<br />sum+=pj<br />if sum&gt;0:<br />p = pselected/sum<br /><br />#if we have a new best path - then remember the index<br />if p &gt; pMax:<br />pMax = p<br />nodeindex = i<br /></pre><p>We have to iterate over all the neighbor nodes in order to choose the right one. For each node the probability of taking the edge going to this node is computed according to the formula given in previous paragraph. Some remarks: the value of the pheromone on each edge is stored in a global array:&nbsp; <strong><em>Land.Edge[nodeFrom][nodeTo]</em></strong>. Also the distances between all nodes are pre-calculated in <strong><em>Land.Distance[nodeFrom][nodeTo]</em></strong>.</p><p>There is quite a lot of code, regarding the visualisation. The <a href="http://wiki.python.org/moin/TkInter">TkInter</a> library was used for drawing. Also the <a href="http://www.pythonware.com/products/pil/">PIL library</a> has to be installed. It should not take too long the figure out the responsibility of each class.</p><h3>The results</h3><p>Here is how the resulting program looks like:</p><p><a href="http://lh3.ggpht.com/-3L4XblYGBBE/T1zScdXFijI/AAAAAAAAARw/1gevOJhd2Xw/s1600-h/image%25255B3%25255D.png"><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://lh5.ggpht.com/-y4SlqUiUlv0/T1zSd4dt24I/AAAAAAAAAR4/FUpcz1PSSRI/image_thumb%25255B1%25255D.png?imgmax=800" width="244" height="213"></a></p><p>And here is the evolution of creating the final decision. First all edges have some amount of pheromone and during the time, the preferred edges are chosen. Because the ants choose the edges randomly on the beginning, the result is never assumed the same. The following three images show the evolution which resulted in quite not optimal solution.</p><p><a href="http://lh6.ggpht.com/-5koEzbzipU4/T1zSehm72cI/AAAAAAAAAR8/r1vd0JpeTeE/s1600-h/image%25255B15%25255D.png"><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://lh4.ggpht.com/-Dc3fPsW8IEI/T1zSfos1p9I/AAAAAAAAASE/Um0dakFeB0U/image_thumb%25255B5%25255D.png?imgmax=800" width="244" height="218"></a></p><p><a href="http://lh5.ggpht.com/-g5eG6ITQjHc/T1zSgO0IoYI/AAAAAAAAASM/PTQ3fMX4wZQ/s1600-h/image%25255B18%25255D.png"><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://lh3.ggpht.com/-ofmOkhVf4Ww/T1zSg-jfcAI/AAAAAAAAASU/f-dmZ_OdcAc/image_thumb%25255B6%25255D.png?imgmax=800" width="244" height="217"></a></p><p><a href="http://lh3.ggpht.com/-ZAi5Gf7Hn4A/T1zShu1IjbI/AAAAAAAAASc/NKhsEWnDG54/s1600-h/image%25255B21%25255D.png"><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://lh5.ggpht.com/-8yZa30YrEBs/T1zSiuTyB_I/AAAAAAAAASk/z3Duu-4TmMw/image_thumb%25255B7%25255D.png?imgmax=800" width="244" height="227"></a></p><p>The quality of the solution depends heavily on the values of the coefficients. These values can be changed in the <strong><em>Program.py</em></strong> file: </p><p><pre class="prettyprint"><br />#level of pheromone to show<br />PToShow = 0.004<br />#factor which lowers the value given to a path on function of the paths length<br />k=1<br />#evaporation factor<br />theta = 0.07<br />#parameter which amplifies the value of the pheromon on the edge (pi^alfa)<br />alfa = 4<br />#parameter which amplifies the impact of the quality of the route  ni^beta; ni=1/de<br />beta = 2.5</pre>Putting aside the coefficients described above, there is also <strong><em>PToShow</em></strong> value, which determines what is the minimal value of pheromone on the edge, in order for the edge to be dotted in the picture.  <p>Before this implementation, I had one before – which was not at all efficient but quite funny. In this implementation the ants, could move freely around – there was no notion of edges. The ants simply took a directions towards a certain node and when they got close enough to it, they considered the node as reached and continued for the other one. This was useless, but I saved these funny graphics with the ants moving all around:</p><p><a href="http://lh4.ggpht.com/-yQucnNihHE4/T1zSju65_1I/AAAAAAAAASw/BwH-UmURFvg/s1600-h/10_1%25255B2%25255D.jpg"><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="10_1" border="0" alt="10_1" src="http://lh6.ggpht.com/-MGjQxWXytvs/T1zSk1HCoVI/AAAAAAAAAS0/SjoMJfcDQBo/10_1_thumb.jpg?imgmax=800" width="172" height="244"></a></p><p>And the ants finding the solution: </p><p><a href="http://lh6.ggpht.com/-PV20LaNIFDo/T1zSlmSncWI/AAAAAAAAAS8/YZeya6WFH8Q/s1600-h/10_2%25255B2%25255D.jpg"><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="10_2" border="0" alt="10_2" src="http://lh3.ggpht.com/-aZbEzgcXkb8/T1zSmW9d--I/AAAAAAAAATE/xOD7TdSJHlo/10_2_thumb.jpg?imgmax=800" width="177" height="244"></a></p><h3>The source code</h3><p><a href="https://github.com/hoonzis/CollectiveInteligence">Download it here.</a></p><p>As said before, the source was created as a module to a larger program and later taken out to be executable isolated. Therefor there still is quite a lot of refactoring which could be done, but I do not consider it necessary, since the purpose is merely to present the Ant colony algorithm.</p><a style="display: none" href="http://www.codeproject.com/script/Articles/BlogFeedList.aspx?amid=honga" rel="tag">CodeProject</a>